{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da0c0308",
   "metadata": {},
   "source": [
    "Genís Lloses 218873 <br>\n",
    "Bernat Treserres 217387 <br>\n",
    "Carla Souto 218871"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acd980a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import defaultdict\n",
    "from array import array\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import collections\n",
    "from numpy import linalg as la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "485bcea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_path = 'dataset_tweets_WHO.txt'\n",
    "with open(docs_path) as fp:\n",
    "    tweets = json.loads(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05337b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            u\"\\U00002700-\\U000027BF\"  # Dingbats\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def remove_symbols_and_links(text):\n",
    "    text = re.sub('https://.*', '', text) # to remove the links\n",
    "    text = re.sub('http://.*', '', text)\n",
    "    for ch in ['&',':','.',',',';','…','-','!','?','¿']:\n",
    "        if ch in text:\n",
    "            text = text.replace(ch, '')\n",
    "    return text\n",
    "\n",
    "def build_terms(line):\n",
    "    \"\"\"\n",
    "    Preprocess the article text (title + body) removing stop words, stemming,\n",
    "    transforming in lowercase and return the tokens of the text.\n",
    "    \n",
    "    Argument:\n",
    "    line -- string (text) to be preprocessed\n",
    "    \n",
    "    Returns:\n",
    "    line - a list of tokens corresponding to the input text after the preprocessing\n",
    "    \"\"\"\n",
    "\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    ## START CODE\n",
    "    line= line.lower() ## Transform in lowercase\n",
    "    line= remove_emoji(line) ## remove emojis\n",
    "    line= remove_symbols_and_links(line) ## remove symbols and links\n",
    "    line= line.split() ## Tokenize the text to get a list of terms\n",
    "    hashtags= [l.replace('#', '') for l in line if '#' in l] # we separate the hashtags\n",
    "    line= [l for l in line if l not in stop_words and l.replace('#', '') not in hashtags and len(l)>1] ## eliminate the stopwords (HINT: use List Comprehension)\n",
    "    line= [stemmer.stem(l) for l in line] ## perform stemming for the keywords\n",
    "    hashtags= [stemmer.stem(l) for l in hashtags] ## perform stemming for the hashtags\n",
    "    line.append(hashtags)\n",
    "    ## END CODE\n",
    "    return line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88714390",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_keywords = {}\n",
    "\n",
    "for key in tweets.keys():\n",
    "    tweets_keywords[int(key)] = build_terms(tweets[key]['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c952837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The right to health means the right to control one’s health and body – including the sexual and reproductive health rights of women and girls – without interference https://t.co/0xs5xwkoTg \n",
      "\n",
      "#HealthForAll #StandUp4HumanRights https://t.co/qfh5PQ8S2D\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['right',\n",
       " 'health',\n",
       " 'mean',\n",
       " 'right',\n",
       " 'control',\n",
       " 'one’',\n",
       " 'health',\n",
       " 'bodi',\n",
       " 'includ',\n",
       " 'sexual',\n",
       " 'reproduct',\n",
       " 'health',\n",
       " 'right',\n",
       " 'women',\n",
       " 'girl',\n",
       " 'without',\n",
       " 'interfer',\n",
       " ['healthforal', 'standup4humanright']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#An example of how the list is stored (in this case, for the last word of the dictionary)\n",
    "\n",
    "print(tweets['2398']['full_text']) # the full text of the tweet\n",
    "tweets_keywords[2398] # the list of keywords and hastags of that tweet"
   ]
  },
 "nbformat": 4,
 "nbformat_minor": 5
}
